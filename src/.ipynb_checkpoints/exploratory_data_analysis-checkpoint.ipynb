{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xenovuseknovate/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning:\n",
      "\n",
      "Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "# This package is used for finding longest common subsequence between two strings\n",
    "# you can write your own dp code for this\n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.manifold import TSNE\n",
    "# Import the Required lib packages for WORD-Cloud generation\n",
    "# https://stackoverflow.com/questions/45625434/how-to-install-wordcloud-in-python3-6\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "if os.path.isfile(\"df_fe_without_preprocessing_train.csv\"):\n",
    "    df = pd.read_csv(\"df_fe_without_preprocessing_train.csv\", encoding=\"latin-1\")\n",
    "    df= df.fillna('')\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"get df_fe_without_preprocessing_train.csv by running the previous notebook\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  freq_qid1  \\\n",
       "0  What is the step by step guide to invest in sh...             0          1   \n",
       "1  What would happen if the Indian government sto...             0          4   \n",
       "2  How can Internet speed be increased by hacking...             0          1   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n",
       "4            Which fish would survive in salt water?             0          3   \n",
       "\n",
       "   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  word_Total  \\\n",
       "0          1     66     57          14          12         10.0        23.0   \n",
       "1          1     51     88           8          13          4.0        20.0   \n",
       "2          1     73     59          14          10          4.0        24.0   \n",
       "3          1     50     65          11           9          0.0        19.0   \n",
       "4          1     76     39          13           7          2.0        20.0   \n",
       "\n",
       "   word_share  freq_q1+q2  freq_q1-q2  \n",
       "0    0.434783           2           0  \n",
       "1    0.200000           5           3  \n",
       "2    0.166667           2           0  \n",
       "3    0.000000           2           0  \n",
       "4    0.100000           4           2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###### Preprocessing of text:\n",
    "-> Removing html tags\n",
    "-> Removing punctuations\n",
    "-> Performing stemming\n",
    "-> Removing stopwords\n",
    "-> Expanding contractions etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the results in 4 decemal points\n",
    "\n",
    "SAFE_DIV = 0.0001\n",
    "STOP_WORDS= stopwords.words(\"english\")\n",
    "\n",
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    pattern = re.compile(\"\\W\")\n",
    "    \n",
    "    if type(x) == type(''):\n",
    "        x= re.sub(pattern, '', x)\n",
    "    if type(x) == type(''):\n",
    "        x= porter.stem(x)\n",
    "        example1= BeautifulSoup(x)\n",
    "        x= example1.get_text()\n",
    "        \n",
    "    return x    \n",
    "    \n",
    "#function to compute and get the features: with 2 parameters of question1 and question2    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Advanced and Feature Extraction(NLP and Fuzzy Features)\n",
    "Definition:\n",
    "    Token:you get a token by splitting sentence by a space\n",
    "    Stop_word: stop words as per NLTK\n",
    "    word: A token that is not a stop_word\n",
    "Features:\n",
    "    cwc_min : Ratio of common_word_count to min lenghth of word count of Q1 and Q2 \n",
    "cwc_min = common_word_count / (min(len(q1_words), len(q2_words)) \n",
    "\n",
    "cwc_max : Ratio of common_word_count to max lenghth of word count of Q1 and Q2 \n",
    "cwc_max = common_word_count / (max(len(q1_words), len(q2_words)) \n",
    "\n",
    "csc_min : Ratio of common_stop_count to min lenghth of stop count of Q1 and Q2 \n",
    "csc_min = common_stop_count / (min(len(q1_stops), len(q2_stops)) \n",
    "\n",
    "csc_max : Ratio of common_stop_count to max lenghth of stop count of Q1 and Q2\n",
    "csc_max = common_stop_count / (max(len(q1_stops), len(q2_stops)) \n",
    "\n",
    "ctc_min : Ratio of common_token_count to min lenghth of token count of Q1 and Q2\n",
    "ctc_min = common_token_count / (min(len(q1_tokens), len(q2_tokens)) \n",
    "\n",
    "\n",
    "ctc_max : Ratio of common_token_count to max lenghth of token count of Q1 and Q2\n",
    "ctc_max = common_token_count / (max(len(q1_tokens), len(q2_tokens)) \n",
    "\n",
    "\n",
    "last_word_eq : Check if First word of both questions is equal or not\n",
    "last_word_eq = int(q1_tokens[-1] == q2_tokens[-1]) \n",
    "\n",
    "\n",
    "first_word_eq : Check if First word of both questions is equal or not\n",
    "first_word_eq = int(q1_tokens[0] == q2_tokens[0]) \n",
    "\n",
    "\n",
    "abs_len_diff : Abs. length difference\n",
    "abs_len_diff = abs(len(q1_tokens) - len(q2_tokens)) \n",
    "\n",
    "\n",
    "mean_len : Average Token Length of both Questions\n",
    "mean_len = (len(q1_tokens) + len(q2_tokens))/2 \n",
    "\n",
    "\n",
    "fuzz_ratio : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
    "\n",
    "\n",
    "fuzz_partial_ratio : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
    "\n",
    "\n",
    "token_sort_ratio : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
    "\n",
    "token_set_ratio : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
    "\n",
    "longest_substr_ratio : Ratio of length longest common substring to min lenghth of token count of Q1 and Q2\n",
    "longest_substr_ratio = len(longest common substring) / (min(len(q1_tokens), len(q2_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_features(q1, q2):\n",
    "    token_features = [0.0]*1.0\n",
    "    \n",
    "    #converting the sentences into tokens:\n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens= q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens)==0:\n",
    "        return token_features\n",
    "    \n",
    "    #get the non-stopwords in questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words= set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #get the stop words in questions:\n",
    "    q1_stops= set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops= set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    #Get the common non-stop words from question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    #get the common stop words from the question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    #get the common tokens for question pair\n",
    "    common_token_count =len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    #last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    #first word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #average token length of both questions\n",
    "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    return token_features\n",
    "\n",
    "#get the longest common sub string\n",
    "\n",
    "def get_longest_substr_ratio(a, b):\n",
    "    strs = list(distance.lcsubstrings(a, b))\n",
    "    if len(strs) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(strs[0]) / (min(len(a), len(b)) + 1)\n",
    "\n",
    "    \n",
    "def extract_features(df):\n",
    "    #preprocessing each question\n",
    "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
    "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
    "    \n",
    "    print(\"token features\")\n",
    "    #merging features with dataset\n",
    "    \n",
    "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    \n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
    "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
    "     #Computing Fuzzy Features and Merging with Dataset\n",
    "    \n",
    "    # do read this blog: http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "    # https://stackoverflow.com/questions/31806695/when-to-use-which-fuzz-function-to-compare-2-strings\n",
    "    # https://github.com/seatgeek/fuzzywuzzy\n",
    "    print(\"fuzzy features..\")\n",
    "\n",
    "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    # The token sort approach involves tokenizing the string in question, sorting the tokens alphabetically, and \n",
    "    # then joining them back into a string We then compare the transformed strings with a simple ratio().\n",
    "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train:\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"nlp_features_train.csv\"):\n",
    "    df=pd.read_csv(\"nlp_features_train.csv\", encoding=\"latin-1\")\n",
    "    df.fillna()\n",
    "else:\n",
    "    print(\"Extracting features for train:\")\n",
    "    df =pd.read_csv(\"/Users/xenovuseknovate/Desktop/machine_learning_project1/Quora_Question_Pair_Similarity/dataset/train.csv\")\n",
    "    df=extract_features(df)\n",
    "    df.to_csv(\"nlp_features_train.csv\", index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
